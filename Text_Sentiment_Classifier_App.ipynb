{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myx4LNabAg-x",
        "outputId": "9ee8aa9e-b103-4a38-f6a3-ef3631215336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q mediapipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O classifier.tflite -q https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\n"
      ],
      "metadata": {
        "id": "jejhAndqAm8x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input text that you wants the model to classify.\n",
        "INPUT_TEXT = \"I'm looking forward to what will come next.\"\n",
        "INPUT_TEXT1 = \"The meeting is scheduled for tomorrow.\""
      ],
      "metadata": {
        "id": "QWH_czuQAtlP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import text\n",
        "\n",
        "# STEP 2: Create an TextClassifier object.\n",
        "base_options = python.BaseOptions(model_asset_path=\"classifier.tflite\")\n",
        "options = text.TextClassifierOptions(base_options=base_options)\n",
        "classifier = text.TextClassifier.create_from_options(options)\n",
        "\n",
        "# STEP 3: Classify the input text.\n",
        "classification_result = classifier.classify(INPUT_TEXT1)\n",
        "\n",
        "# STEP 4: Process the classification result. In this case, print out the most likely category.\n",
        "top_category = classification_result.classifications[0].categories[0]\n",
        "print(f'{top_category.category_name} ({top_category.score:.2f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmIsdu-jAx2n",
        "outputId": "5cc0a4d9-325c-4ed2-f95f-f12f7da8b72b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive (0.56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit APP"
      ],
      "metadata": {
        "id": "DmcerbxtCzRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uk2fmFDCyoX",
        "outputId": "85fa53dd-acc8-4ba3-ea41-75cdf7e98e81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        ""
      ],
      "metadata": {
        "id": "PdXnm6zjC8zm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the Ngrok API key securely\n",
        "ngrok_api_key = userdata.get('NGROK_API')\n",
        "\n",
        "if ngrok_api_key:\n",
        "    # Authenticate Ngrok with the API key\n",
        "    ngrok.set_auth_token(ngrok_api_key)\n",
        "    print(\"Ngrok authenticated successfully!\")\n",
        "else:\n",
        "    print(\"Ngrok API key not found. Please add it in the Colab settings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB1EwgH0DAW2",
        "outputId": "0782b74a-c024-4663-bee2-db61dd195b25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok authenticated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ngrok token here\n",
        "ngrok.set_auth_token(ngrok_api_key)"
      ],
      "metadata": {
        "id": "TX86E_ozDEMG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import text\n",
        "\n",
        "# Initialize the classifier with the model\n",
        "base_options = python.BaseOptions(model_asset_path=\"classifier.tflite\")\n",
        "options = text.TextClassifierOptions(base_options=base_options)\n",
        "classifier = text.TextClassifier.create_from_options(options)\n",
        "\n",
        "# Streamlit app\n",
        "st.title('Text Sentiment Classifier')\n",
        "\n",
        "# User input\n",
        "user_input = st.text_input(\"Enter a sentence:\")\n",
        "\n",
        "if user_input:\n",
        "    # Classify input text\n",
        "    classification_result = classifier.classify(user_input)\n",
        "    top_category = classification_result.classifications[0].categories[0]\n",
        "\n",
        "    # Display result with percentage\n",
        "    sentiment = top_category.category_name\n",
        "    confidence = top_category.score\n",
        "\n",
        "    # Set color based on sentiment\n",
        "    if sentiment.lower() == 'positive':\n",
        "        color = \"green\"\n",
        "    else:\n",
        "        color = \"red\"\n",
        "\n",
        "    # Display the result\n",
        "    st.markdown(f\"### Sentiment: {sentiment.capitalize()} ({confidence * 100:.2f}%)\")\n",
        "    st.markdown(f'<div style=\"background-color:{color}; padding: 10px; border-radius: 5px; color: white; font-size: 20px;\">{sentiment.capitalize()} - {confidence * 100:.2f}%</div>', unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mxC59AtDHeQ",
        "outputId": "58ec992d-251c-4c88-83ac-76deb3f484f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "    # Change the port if 8501 is already in use or if you prefer another port\n",
        "    os.system('streamlit run /content/app.py --server.port 8501')"
      ],
      "metadata": {
        "id": "d9zRManGDLFb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a thread to run the Streamlit app\n",
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()\n",
        ""
      ],
      "metadata": {
        "id": "-YQHwjGSDS6B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "print('Your Streamlit app is live at:', public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geTVbmaODXWe",
        "outputId": "5e0ebe0a-3e49-4db7-ed58-403a14260ed4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is live at: NgrokTunnel: \"https://14b0-35-238-23-50.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "tbe98mRKDaTX"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}